---
- hosts: all
  become: yes
  become_user: root
  vars_files:
  - variables.yaml
  tasks:
  - name: Replace hosts file
    tags: install-depedencies
    copy:
      src: ../templates/hosts.txt
      dest: /etc/hosts
      mode: 0644
  - name: Update hosts file
    tags: install-depedencies
    blockinfile:
      path: /etc/hosts
      block: |
        {% for host in groups['all'] %}
        {{ hostvars[host].ansible_host }} {{ hostvars[host].ansible_hostname }} {{ host }}
        {% endfor %}
      mode: 0644
  - name: Kill APT process if any
    tags: 
    - install-depedencies
    - kill-dpkg-process
    shell: |
      killall -9 /usr/bin/dpkg
      rm -rf /var/cache/debconf/*
  - name: Unhold Snapd packages
    tags: install-depedencies
    dpkg_selections:
      name: snapd
      selection: install
  - name: Uninstall Snapd packages
    tags: install-depedencies
    apt:
      name: snapd
      state: absent
      update_cache: yes
    environment: "{{ PROXY }}"
  - name: Update Ubuntu packages
    tags: install-depedencies
    apt:
      update_cache: yes
      upgrade: dist
      force_apt_get: yes
      autoremove: yes
      install_recommends: true
      dpkg_options: 'force-confdef,force-confold'
    environment: "{{ PROXY }}"
  - name: Install depedency
    tags: install-depedencies
    apt:
      name: "{{ packages }}"
      update_cache: yes
      state: present
    vars:
      packages:
      - apt-transport-https
      - ca-certificates
      - curl
      - gnupg
      - lsb-release
      - nfs-common
      - glusterfs-client
      - tree
      - jq
      - sysstat
      - iperf
      - arping
      - ca-certificates
      - net-tools
      - dnsutils
      - traceroute
    environment: "{{ PROXY }}"

- hosts: storages
  become: yes
  become_user: root
  vars_files:
  - variables.yaml
  tasks:
  - name: Install NFS Server
    tags: install-depedencies
    apt:
      name: "nfs-kernel-server"
      update_cache: yes
      state: present
    environment: "{{ PROXY }}"


- hosts: masters,workers
  become: yes
  become_user: root
  vars_files:
  - variables.yaml
  tasks:
  - name: Load required containerd modules
    tags: install-containerd
    copy:
      dest: /etc/modules-load.d/containerd.conf
      content: |
        overlay
        br_netfilter
    register: load_containerd_modules
  - name: Load required sysctl parameters
    tags: install-containerd
    copy:
      dest: /etc/sysctl.d/99-kubernetes-cri.conf
      content: |
        net.bridge.bridge-nf-call-iptables  = 1
        net.bridge.bridge-nf-call-ip6tables = 1
        net.ipv4.ip_forward                 = 1
  - name: Add containerd apt signing key
    tags: install-containerd
    shell: |
      sed -i 's/net.ipv4.ip_forward=0/#net.ipv4.ip_forward=0/g' /etc/sysctl.conf
    register: load_sysctl_parameters
  - name: Apply modules and parameters
    tags: install-containerd
    shell: |
      modprobe overlay
      modprobe br_netfilter
      sysctl --system
    when: load_containerd_modules.changed or load_sysctl_parameters.changed
  - name: Remove uncompatible Containerd
    tags: install-containerd
    apt:
      name: containerd
      state: absent
  - name: Set DPKG architecture
    tags: install-containerd
    set_fact:
      dpkg_arch: "{{ 'amd64' if ansible_architecture == 'x86_64' else ansible_architecture }}"
  - name: Add containerd apt signing key
    tags: install-containerd
    apt_key:
      url: https://download.docker.com/linux/ubuntu/gpg
      state: present
    environment: "{{ PROXY }}"
  - name: Add containerd apt repository
    tags: install-containerd
    apt_repository:
      repo: deb [arch={{ dpkg_arch }}] https://download.docker.com/linux/ubuntu {{ ansible_distribution_release }} stable
      state: present
      filename: docker
    environment: "{{ PROXY }}"
  - name: Install containerd packages
    tags: install-containerd
    apt:
      name: containerd.io
      state: present
    environment: "{{ PROXY }}"
  - name: Create Containerd directories
    tags: install-containerd
    file:
      path: /etc/containerd
      state: directory
  - name: Writing Containerd configuration
    tags: install-containerd
    copy:
      src: ../templates/containerd-config.toml
      dest: /etc/containerd/config.toml
    register: containerd_configuration
  - name: Create proxy directory for Containerd
    tags: install-containerd
    file:
      path: /etc/systemd/system/containerd.service.d
      state: directory
      mode: 0755
  - name: Writing proxy config for Containerd
    tags: install-containerd
    template:
      src: ../templates/http-proxy.conf.j2
      dest: /etc/systemd/system/containerd.service.d/http-proxy.conf
      mode: 0644
    register: containerd_proxy_config
  - name: Restarting Containerd service
    tags: install-containerd
    systemd:
      name: containerd
      daemon_reload: true
      masked: false
      enabled: true
      state: restarted
    when: containerd_configuration.changed or containerd_proxy_config.changed


  - name: Remove swapfile from /etc/fstab
    tags: install-kubernetes
    mount:
      name: "{{ item }}"
      fstype: swap
      state: absent
    with_items:
      - swap
      - none
  - name: Disable swap
    tags: install-kubernetes
    command: swapoff -a
    when: ansible_swaptotal_mb > 0
  - name: Add kubernetes apt signing key
    tags: install-kubernetes
    apt_key:
      url: https://github.com/jhodysetiawansekardono/projects-kubernetes/raw/main/apt-key/kubernetes.gpg
      state: present
    environment: "{{ PROXY }}"
  - name: Add kubernetes apt repository
    tags: install-kubernetes
    apt_repository:
      repo: deb https://apt.kubernetes.io/ kubernetes-xenial main
      state: present
      filename: kubernetes.list
    environment: "{{ PROXY }}"
  - name: Install kubernetes packages
    tags: install-kubernetes
    apt:
      name: "{{ packages }}"
      state: present
      update_cache: yes
    vars:
      packages:
        - kubelet=1.26.1-00
        - kubeadm=1.26.1-00
        - kubectl=1.26.1-00
    environment: "{{ PROXY }}"

- hosts: masters
  become: yes
  become_user: root
  vars_files:
  - variables.yaml
  tasks:
  - name: Set DPKG architecture
    tags: install-kubernetes
    set_fact:
      dpkg_arch: "{{ 'amd64' if ansible_architecture == 'x86_64' else ansible_architecture }}"
  - name: Add Helm apt signing key
    tags: install-kubernetes
    apt_key:
      url: https://baltocdn.com/helm/signing.asc
      state: present
    environment: "{{ PROXY }}"
  - name: Add Helm apt repository
    tags: install-kubernetes
    apt_repository:
      repo: deb [arch={{ dpkg_arch }}] https://baltocdn.com/helm/stable/debian/ all main
      state: present
      filename: helm-stable
    environment: "{{ PROXY }}"
  - name: Install Helm packages
    tags: install-kubernetes
    apt:
      name: helm
      state: present
      update_cache: yes
    environment: "{{ PROXY }}"
  - name: Disable auto update of kubernetes packages
    tags: install-kubernetes
    dpkg_selections:
      name: "{{ item }}"
      selection: hold
    loop:
      - kubelet
      - kubeadm
      - kubectl
      - containerd.io
      - helm


- hosts: loadbalancers
  become: yes
  become_user: root
  vars_files:
  - variables.yaml
  tasks:
  - name: Install loadbalancer packages
    tags: install-loadbalancer
    apt:
      name: haproxy
      update_cache: yes
      state: present
    environment: "{{ PROXY }}"
  - name: Disable auto updates for loadbalancer packages
    tags: install-loadbalancer
    dpkg_selections:
      name: haproxy
      selection: hold
  - name: Writing loadbalancer configuration
    tags: install-loadbalancer
    template:
      src: ../templates/haproxy.cfg.j2
      dest: /etc/haproxy/haproxy.cfg
    register: configuring_loadbalancer
  - name: Apply loadbalancer configuration
    tags: install-loadbalancer
    systemd:
      name: haproxy
      state: restarted
    when: configuring_loadbalancer.changed


- hosts: master001
  become: yes
  become_user: root
  vars_files:
  - variables.yaml
  tasks:
  - name: Creating kubeadm config file
    tags: bootstrap-cluster
    template:
      src: ../manifests/kubeadm/kubernetes-1.26.1.yaml.j2
      dest: /root/kubeadm-config.yaml
  - name: Check if kubeadm has been initialized
    tags: bootstrap-cluster
    stat:
      path: /etc/kubernetes/kubelet.conf
    register: kubeadm_initialized_status
  - name: Initialize the first control plane
    tags: bootstrap-cluster
    shell: |
      kubeadm init --config /root/kubeadm-config.yaml
    when: not kubeadm_initialized_status.stat.exists
  - name: Writing CNI manifest
    tags: bootstrap-cluster
    copy:
      src: ../manifests/cni/calico-v3.25.yaml
      dest: /root/calico.yaml
  - name: Create kubeconfig directory
    tags: bootstrap-cluster
    file:
      path: /home/ubuntu/.kube
      state: directory
      group: ubuntu
      owner: ubuntu
  - name: Writing kubeconfig manifest
    tags: bootstrap-cluster
    copy:
      src: /etc/kubernetes/admin.conf
      dest: /home/ubuntu/.kube/config
      group: ubuntu
      owner: ubuntu
      mode: 0600
      remote_src: true
  - name: Apply CNI
    tags: bootstrap-cluster
    shell: |
      KUBECONFIG=/etc/kubernetes/admin.conf kubectl apply -f /root/calico.yaml


  - name: Generate join command for control-plane
    tags: generate-token
    shell: echo "$(kubeadm token create --print-join-command) --control-plane --certificate-key $(kubeadm init phase upload-certs --upload-certs | grep -vw -e certificate -e Namespace)"
    register: join_command_controller
  - name: Copy join command for control-plane to local file
    tags: generate-token
    local_action: copy content="{{ join_command_controller.stdout_lines[0] }}" dest="./join-command-controller"
  - name: Generate join command for workers
    tags: generate-token
    command: kubeadm token create --print-join-command
    register: join_command_workers
  - name: Copy join command for workers to local file
    tags: generate-token
    local_action: copy content="{{ join_command_workers.stdout_lines[0] }}" dest="./join-command-workers"


- hosts: master002,master003
  become: yes
  become_user: root
  tasks:
  - name: Copy the join command to control plane
    tags: join-masters
    copy:
      mode: 0777
      src: join-command-controller
      dest: /tmp/join-command.sh
  - name: Join the control plane node to cluster
    tags: join-masters
    command: sh /tmp/join-command.sh
  - name: Create kubeconfig directory
    tags: join-masters
    file:
      path: /home/ubuntu/.kube
      state: directory
      group: ubuntu
      owner: ubuntu
  - name: Writing kubeconfig manifest
    tags: join-masters
    copy:
      src: /etc/kubernetes/admin.conf
      dest: /home/ubuntu/.kube/config
      group: ubuntu
      owner: ubuntu
      mode: 0600
      remote_src: true


- hosts: workers
  become: yes
  become_user: root
  vars_files:
  - variables.yaml
  tasks:
  - name: Copy the join command to workers
    tags: join-workers
    copy:
      mode: 0777
      src: join-command-workers
      dest: /tmp/join-command.sh
  - name: Join the workers node to cluster
    tags: join-workers
    command: sh /tmp/join-command.sh
- hosts: localhost
  connection: local
  tasks:
  - name: Removing join command
    tags: join-workers
    file:
      path: "{{ item }}"
      state: absent
    with_items:
      - join-command-controller
      - join-command-workers
- hosts: master001
  tasks:
  - name: Labeling worker nodes
    tags: join-workers
    shell: |
      for hosts in $(kubectl get nodes -o=custom-columns=NAME:.metadata.name --no-headers | grep 'worker-0[1-4]'); do kubectl label nodes $hosts type=app; kubectl label nodes $hosts node-role.kubernetes.io/worker=; kubectl label nodes $hosts node.kubernetes.io/ingress-controller=true; done
      for hosts in $(kubectl get nodes -o=custom-columns=NAME:.metadata.name --no-headers | grep worker-05); do kubectl label nodes $hosts type=ops-monit; kubectl label nodes $hosts node-role.kubernetes.io/monitoring=; kubectl taint node $hosts node-role.kubernetes.io/monitoring:NoSchedule; done
  - name: Waiting cluster ready
    tags: join-workers
    pause:
      echo: yes
      minutes: 10


- hosts: masters,workers
  become: yes
  become_user: root
  tags: fixing-apiserver
  tasks:
  - name: Configure kubelet
    shell: |
      sed -i 's/server: https:\/\/localhost:6443/server: https:\/\/172.19.40.9:6443/g' /etc/kubernetes/kubelet.conf
    when: fixing_apiserver.changed
  - name: Apply Kubeadm changes
    systemd:
      name: kubelet
      daemon_reload: true
      state: restarted
    when: fixing_apiserver.changed
  - name: Waiting
    pause:
      echo: yes
      seconds: 30


- hosts: workers
  become: yes
  become_user: root
  vars_files:
  - variables.yaml
  tasks:
  - name: Writing loadbalancer static POD manifest
    tags: configure-apiserver
    copy:
      src: ../manifests/loadbalancer/nginx.yaml
      dest: /etc/kubernetes/manifests
      mode: 0600
  - name: Create loadbalancer directories
    tags: configure-apiserver
    file:
      path: /etc/nginx
      state: directory
  - name: Writing loadbalancer configuration
    tags: configure-apiserver
    template:
      src: ../templates/nginx.conf.j2
      dest: /etc/nginx/nginx.conf
  - name: Waiting Loadbalancer Running
    pause:
      echo: yes
      seconds: 60

- hosts: masters,workers
  become: yes
  become_user: root
  tasks:
  - name: Writing kubelet config for masters
    tags: configure-apiserver
    template:
      src: ../manifests/kubelet/kubelet-config.yaml.j2
      dest: /var/lib/kubelet/config.yaml
      mode: 0644
    register: configure_kubelet
  - name: Configure Kubeadm to use localhost loadbalancer
    tags: configure-apiserver
    shell: |
      sed -i 's/server: https:\/\/[0-9]\+\.[0-9]\+\.[0-9]\+\.[0-9]\+:6443/server: https:\/\/localhost:6443/g' /etc/kubernetes/kubelet.conf
    register: configuring_apiserver
  - name: Apply Kubeadm changes
    tags: configure-apiserver
    systemd:
      name: kubelet
      daemon_reload: true
      state: restarted
    when: configuring_apiserver.changed or configure_kubelet.changed

- hosts: master001
  become: yes
  become_user: root
  tasks:
  - name: Configure static POD to use localhost apiserver
    tags: configure-apiserver
    shell: |
      KUBECONFIG=/etc/kubernetes/admin.conf kubectl -n kube-system get configmap kubeadm-config -o jsonpath='{.data.ClusterConfiguration}' > /root/kubeadm.yaml
      sed -i 's/controlPlaneEndpoint: [0-9.]\+:/controlPlaneEndpoint: localhost:/g' /root/kubeadm.yaml
      kubeadm init phase upload-config kubeadm --config kubeadm.yaml
      KUBECONFIG=/etc/kubernetes/admin.conf kubectl -n kube-system get cm kube-proxy -o yaml > /root/kube-proxy.yaml
      KUBECONFIG=/etc/kubernetes/admin.conf kubectl -n kube-public get cm cluster-info -o yaml > /root/cluster-info.yaml
      sed -i 's/server: https:\/\/[0-9\.]\{1,\}:6443/server: https:\/\/localhost:6443/' /root/kube-proxy.yaml /root/cluster-info.yaml
      KUBECONFIG=/etc/kubernetes/admin.conf kubectl apply --force -f /root/cluster-info.yaml
      KUBECONFIG=/etc/kubernetes/admin.conf kubectl apply --force -f /root/kube-proxy.yaml
      KUBECONFIG=/etc/kubernetes/admin.conf kubectl rollout restart ds kube-proxy -n kube-system
      KUBECONFIG=/etc/kubernetes/admin.conf kubectl rollout status ds kube-proxy -n kube-system
  - name: Cleaning manifest
    tags: configure-apiserver
    file:
      path: "{{ item }}"
      state: absent
    with_items:
      - /root/cluster-info.yaml
      - /root/kube-proxy.yaml
      - /root/kubeadm-config.yaml
      - /root/kubeadm.yaml
      - /root/calico.yaml
- hosts: masters
  serial: 1
  become: yes
  become_user: root
  tasks:
  - name: Restarting API server
    tags: 
    - configure-apiserver
    - restart-api
    shell: |
      mkdir -p /root/backups/manifests/
      mv /etc/kubernetes/manifests/kube-apiserver.yaml /root/backups/manifests/
      sed -i 's/server: https:\/\/[0-9\.]\{1,\}:6443/server: https:\/\/localhost:6443/' /home/ubuntu/.kube/config /etc/kubernetes/admin.conf
  - name: Waiting API shutdown
    tags: 
    - configure-apiserver
    - restart-api
    pause:
      echo: yes
      seconds: 30
  - name: Start API server
    tags:
    - configure-apiserver
    - restart-api
    shell: |
      mv /root/backups/manifests/kube-apiserver.yaml /etc/kubernetes/manifests/kube-apiserver.yaml
      rm -rf /root/backups/manifests/
  - name: Waiting API Started
    tags: 
    - configure-apiserver
    - restart-api
    pause:
      echo: yes
      seconds: 30
